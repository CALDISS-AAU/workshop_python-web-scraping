{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Web Scraping with Python\n",
    "\n",
    "This notebook introduces the basic tools for web scraping with Python:\n",
    "- Accessing a webpage\n",
    "- Extracting source code from a webpage (HTML)\n",
    "- Parsing and navigating HTML with `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the internet with Python\n",
    "\n",
    "The package `requests` can be used to send requests over the internet. \n",
    "\n",
    "When visiting a webpage, you are sending a \"get\" request to the server where the webpage is hosted. \n",
    "\n",
    "In Python, a get request can be send with `requests.get(url)`. This returns a request object (or a class) containing various attributes like the status code, headers and content.\n",
    "\n",
    "In the code below, we send a request to the news overview for the EU's Climate Action section (https://ec.europa.eu/clima/news_en)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # Importing the package\n",
    "\n",
    "response = requests.get(\"https://ec.europa.eu/clima/news_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`response` is now a request object containing various information of that request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the request\n",
    "\n",
    "To check if the request was successful, we can check the status code by inspecting the attribute `.status_code`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status code 200 means \"OK\"; that our request was succesul. \n",
    "\n",
    "This can be verified by checking the attribute `.reason`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n"
     ]
    }
   ],
   "source": [
    "print(response.status_code, response.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick note on status codes**\n",
    "\n",
    "- Status codes beginning with 2 or 3: The request is successful\n",
    "- Status codes beginning with 4: The request has failed (client-side, fx 404 when specifying a URL that does not exist on a given domain).\n",
    "- Status codes beginning with 5: The request has failed (server-side)\n",
    "\n",
    "Status codes can be used in code to check whether or not a site is reached before scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content of a webpage\n",
    "\n",
    "The raw source code from a webpage can be extracted from the attribute `.content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\\n<link rel=\"shortcut icon\" href=\"https://ec.europa.eu/clima/sites/clima/themes/clima_theme/favicon.ico\" type=\"image/vnd.microsoft.icon\" />\\n<meta name=\"description\" content=\"Climate Action -\" />\\n<meta name=\"keywords\" content=\"European Commission, European Union, EU\" />\\n<meta name=\"robots\" content=\"follow, index\" />\\n<meta name=\"generator\" content=\"Drupal 7 (https://drupal.org)\" />\\n<link rel=\"canonical\" href=\"https://ec.europa.eu/clima/news_en\" />\\n<link rel=\"shortlink\" href=\"https://ec.europa.eu/clima/news_en\" />\\n<meta http-equiv=\"content-language\" content=\"en\" />\\n<meta name=\"revisit-after\" content=\"15 days\" />\\n<meta property=\"og:site_name\" content=\"Climate Action - European Commission\" />\\n<meta property=\"og:type\" content=\"website\" />\\n<meta property=\"og:url\" content=\"https://ec.europa.eu/clima/news_en\" />\\n<meta property=\"og:title\" content=\"News\" />\\n<meta property=\"og:description\"'\n"
     ]
    }
   ],
   "source": [
    "content = response.content\n",
    "print(content[0:1000]) # Printing first 1000 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this raw source code, one *could* process this as is using something like regular expression to find the relevant parts of the source code.\n",
    "\n",
    "However, HTML has a certain structure. This can be utilized to extract specific information from a webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick introduction to HTML\n",
    "\n",
    "Instead of processing the HTML as raw text, we can utilize the structure of HTML to extract specific parts of a webpage.\n",
    "\n",
    "This requires some knowledge of what HTML is and how it is structured.\n",
    "\n",
    "HTML is short for \"Hyper-Text Markup Language\". It is used on webpages to give the pages their structure.\n",
    "\n",
    "HTML is structured in \"tags\" denoted by `<>` and `</>`. The tags denote what kind of content it is. `<p>` is for example a paragraph tag. A piece of HTML like: `<p> This is a paragraph </p>` will render the sentence \"This is a paragraph\" as a paragraph. Common tags include `h1` for headings (and `h2`, `h3` and so on), `a` for links and `div` for a \"division\" or \"section\".\n",
    "\n",
    "HTML is structured in a tree-like structure. Tags are therefore usually located within other tags. Tags on the same level are refered to as \"siblings\", tags inside other tags are refered to as \"children\" and tags outside other tags are refered to as \"parents\".\n",
    "\n",
    "HTML uses \"attributes\" to both differentiate between the same type of tags and to add other variables/information to the tag. The `id` attribute is fx used to give several tags a common id. `class` is used to differentiate between different tags and provide them with different stylings. A common and useful attribute is `href` which contain the link that a hyperlink is refering to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    <html>\n",
    "        <body>\n",
    "            <div id=\"convo1\">\n",
    "                <p class=\"kenobi\">Hello There!</p>\n",
    "            </div>\n",
    "            <div id=\"convo2\">\n",
    "                <p class=\"grievous\">General Kenobi!</p>\n",
    "            </div>\n",
    "            <div id=\"convo3\">\n",
    "                <p class=\"kenobi\">So Uncivilized!</p>\n",
    "            </div>\n",
    "        </body>\n",
    "    </html>\n",
    "```    \n",
    "\n",
    "\n",
    "The code above is an example of HTML code. Rendered as a webpage it would only contain the text within the tags:\n",
    "\n",
    "```\n",
    "Hello There!\n",
    "\n",
    "General Kenobi!\n",
    "\n",
    "So Uncivilized!\n",
    "```\n",
    "\n",
    "The structure and the tags of the HTML allows us to extract only specific parts of the code. This is because the structure and the tags makes certain part of the code uniquely identifiable. For example:\n",
    "\n",
    "- The text \"Hello There!\" is located within a p tag with the class \"kenobi\". \n",
    "- The p tag containing the text \"Hello There!\" is located within the div tag with id \"convo1\" (tags located inside other tags are refered to as \"children\")\n",
    "- The div tag with id \"convo1\" is located next to another div tag with id \"convo2\" (tags located next to each other or on the same level are refered to as \"siblings\")\n",
    "\n",
    "Combining the information, we can uniquely refer to the tag containing \"Hello There!\" by specifying that we want a p tag with class \"kenobi\" that is a child of a div tag with id \"convo1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing HTML with BeautifulSoup\n",
    "\n",
    "The package \"BeautifulSoup\" (https://www.crummy.com/software/BeautifulSoup/bs4/doc/) is developed specifically to navigate and parsing HTML (and XML) code. It works by converting HTML code to a \"soup-object\" wherein specific parts of the HTML can be extracted by refering to specific tags or paths.\n",
    "\n",
    "The code below converts the HTML from before to a soup object using the function `bs`, which is a shorthand for the function `BeautifulSoup` imported from `bs4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <div id=\"convo1\">\n",
      "   <p class=\"kenobi\">\n",
      "    Hello There!\n",
      "   </p>\n",
      "  </div>\n",
      "  <div id=\"convo2\">\n",
      "   <p class=\"grievous\">\n",
      "    General Kenobi!\n",
      "   </p>\n",
      "  </div>\n",
      "  <div id=\"convo3\">\n",
      "   <p class=\"kenobi\">\n",
      "    So Uncivilized!\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "html = '<html><body><div id=\"convo1\"><p class=\"kenobi\">Hello There!</p></div><div id=\"convo2\"><p class=\"grievous\">General Kenobi!</p></div><div id=\"convo3\"><p class=\"kenobi\">So Uncivilized!</p></div></body></html>'\n",
    "soup = bs(html, \"html.parser\") # The second arguement specifies the parser to use; how the code should be interpreted\n",
    "print(soup.prettify()) # Prints the HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When printed with `.prettify()` it looks like the same text but we are now able to navigate it using the tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding tags\n",
    "\n",
    "The methods `.find()` and `.find_all()` are used to find the first match and all matches respectively. The first argument of the method is the tag. Other arguments can then be added to make the search more specific.\n",
    "\n",
    "Note that `.find()` and `.find_all()` are methods tied to a soup object, so they have to be used with some object returned from `bs` (in this case the object `soup` created earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"kenobi\">Hello There!</p>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\") # Finds the first p tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.find()` returns a new soup object with the HTML in the first matched tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"kenobi\">Hello There!</p>,\n",
       " <p class=\"grievous\">General Kenobi!</p>,\n",
       " <p class=\"kenobi\">So Uncivilized!</p>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\") # Finds all p tags (returned as a list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.find_all()` returns a list of soup objects with the HTML in the matched tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `.get_text()` extracts the actual textual content within the tag (between `<p>` and `</p>` in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello There!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\").get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.get_text()` works on a soup object and therefore not on returns from `find_all()`, as that returns a list. To extract the text from the contents of a list returned from `find_all()`, we have to iterate over the list elements (fx with a for loop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello There!\n",
      "General Kenobi!\n",
      "So Uncivilized!\n"
     ]
    }
   ],
   "source": [
    "for tag in soup.find_all(\"p\"):\n",
    "    print(tag.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using attributes to find tags\n",
    "\n",
    "In addition to searching for tags, we can also specify attributes. Some attributes have arguments specific for them like id and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello There!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"div\", id = \"convo1\").get_text() # Search for a specific id attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `.get_text()` extracts *all* text within the tag including text within child tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for class attribute (notice the `_` added to `class_` as the `class` name is reserved somewhere else in Python):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello There!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\", class_ = \"kenobi\").get_text() # Search for a specific class attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags can also be found by searching for the attribute alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello There!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(class_ = \"kenobi\").get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup supports a wide range of attributes (id, href, class). There are however no real rules as to what attributes can be called in HTML. BeautifulSoup therefore supports searching for any attribute with the following syntax:\n",
    "\n",
    "`attrs = {\"attribute\": \"value\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello There!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(attrs = {\"class\": \"kenobi\"}).get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knowledge check:\n",
    "\n",
    "What tags or attributes can be used to extract the text \"General Kenobi\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <div id=\"convo1\">\n",
      "   <p class=\"kenobi\">\n",
      "    Hello There!\n",
      "   </p>\n",
      "  </div>\n",
      "  <div id=\"convo2\">\n",
      "   <p class=\"grievous\">\n",
      "    General Kenobi!\n",
      "   </p>\n",
      "  </div>\n",
      "  <div id=\"convo3\">\n",
      "   <p class=\"kenobi\">\n",
      "    So Uncivilized!\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding search using regex\n",
    "\n",
    "Attribute values can be long and sometimes adhere to a structure, where we want to find all attributes starting with some value. \n",
    "\n",
    "Instead of passing an exact string match as an arguement for `.find()`, one can instead parse a compiled regular expression pattern to search for.\n",
    "\n",
    "We will not fully explain regular expression here but put shortly, regular expressions is a syntax for writing patterns that can match text strings. Instead of searching specifically for \"kenobi\", one could search for a pattern like starting with \"ken\" (`\"^ken\"`), ends with \"obi\" (`\".*obi$\"`) or contains six letters (`\"\\w{6}\"`).\n",
    "\n",
    "Regular expressions can be compiled using `re.compile(pattern)`. This pattern can the be used in `.find()` and `.find_all()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"grievous\">General Kenobi!</p>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "soup.find(class_=re.compile(\"^gri\")) # Search for tags with a class attribute starting with \"gri\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for specific text\n",
    "\n",
    "The `.find()` and `.find_all()` methods have a `string = ` arguement to search for specific strings in the text of the HTML. Regular expressions can be used here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello There!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(string = re.compile(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigating the HTML structure\n",
    "\n",
    "Using `.find()` returns a new soup object (`.find_all()` a list of soup objects). Because these methods search for tags *within* the soup object, it is always child tags of the original soup that is returned.\n",
    "\n",
    "This allows one to parse further by first specifying one tag and then another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"kenobi\">Hello There!</p>\n"
     ]
    }
   ],
   "source": [
    "soup_child = soup.find(\"div\")\n",
    "\n",
    "soup_grandchild = soup_child.find(\"p\")\n",
    "\n",
    "print(soup_grandchild)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also allows one to navigate the structure, as the extracted soup objects maintains references to the HTML structure that it was extracted from.\n",
    "\n",
    "Using `.parent`, one can locate the tag in which a certain tag is located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"kenobi\">Hello There!</p>\n",
      "<div id=\"convo1\"><p class=\"kenobi\">Hello There!</p></div>\n"
     ]
    }
   ],
   "source": [
    "soup_child = soup.find(\"p\", class_ = \"kenobi\")\n",
    "\n",
    "print(soup_child)\n",
    "\n",
    "print(soup_child.parent) # Returns the parent of soup_child (a div tag in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also iterate over all parents (and grand parents, so to speak) with `.parents`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div\n",
      "body\n",
      "html\n",
      "[document]\n"
     ]
    }
   ],
   "source": [
    "for parent in soup_child.parents:\n",
    "    print(parent.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `.next_sibling` and `.previous_sibling` you can navigate between tags on the same level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div id=\"convo1\"><p class=\"kenobi\">Hello There!</p></div>\n",
      "<div id=\"convo2\"><p class=\"grievous\">General Kenobi!</p></div>\n"
     ]
    }
   ],
   "source": [
    "soup_child = soup.find(\"div\")\n",
    "\n",
    "print(soup_child)\n",
    "\n",
    "print(soup_child.next_sibling) # Returns the next tag on the same level as soup_child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the right tags\n",
    "\n",
    "Let us try applying some of these skills on the European Union Climate Action news section.\n",
    "\n",
    "We already know how to get the HTML, so this just has to be converted to a soup object, and we are ready to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://ec.europa.eu/clima/news_en\")\n",
    "\n",
    "eu_html = response.content\n",
    "\n",
    "eu_soup = bs(eu_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the right tags by just browing through raw HTML is not ideal.\n",
    "\n",
    "Instead we can use our browser to help us find the parts of the webpage to extract. Almost all browsers has an \"inspector tool\" of some kind that allows one to inspect the source code of a webpage (shortcut `F12` for a lot of browsers on Windows and `Command-Option-I` for Safari on Mac)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting news headlines from EU Climate Action News\n",
    "\n",
    "Inspecting the HTML of https://ec.europa.eu/clima/news_en, we see that the headlines are part of an \"a\" tag within a span tag with the class \"views-field\". This class is however not unique. Going up a level further, there is another span tag with the class \"views-field-title\", which does seem to be unique for the headlines.\n",
    "\n",
    "We can extract the first headline as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Further action required to meet 2020 fuel quality targets despite 3.7% drop in greenhouse gas intensity since 2010\n"
     ]
    }
   ],
   "source": [
    "news_title_soup = eu_soup.find(\"span\", class_ = \"views-field-title\").find(\"a\") # The find methods are chained; first span, then a\n",
    "\n",
    "print(news_title_soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the span tag in question actually contains two classes: \"views-field\" and \"views-field-title\". HTML class names cannot contain spaces, so when an HTML tag contains a class attribute that contains spaces, it is actually two classes. When specifying the class with `.find()` or `.find_all()`, we only have to specify one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The headline is also a link. Links are almost always created as an \"a\" tag.\n",
    "\n",
    "`news_title_soup` is currently the soup object with the \"a\" tag containing the headline. Supposing we want to collect the links to the articles to scrape the articles themselves, we can extract that directly from this soup object.\n",
    "\n",
    "The URL linked is almost always stored as an \"href\" attribute in an \"a\" tag.\n",
    "\n",
    "Attributes can be extracted directly from soup objects using `[attribute]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/clima/news/further-action-required-meet-2020-fuel-quality-targets-despite-37-drop-greenhouse-gas-intensity_en'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_title_soup['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links can be either \"absolute\" or \"relative\". Absolute links contain the entire URL to access the page. A relative URL contains the path on the specific domain. \n",
    "\n",
    "In order to convert the output a both to a working URL, we have to add the main domain, which can be done via pasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ec.europa.eu/clima/news/further-action-required-meet-2020-fuel-quality-targets-despite-37-drop-greenhouse-gas-intensity_en\n"
     ]
    }
   ],
   "source": [
    "print(\"https://ec.europa.eu\" + news_title_soup['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting all headlines\n",
    "\n",
    "Extracting all the titles will have to be done step-wise, as `.find_all()` cannot be chained the same way because `.find_all()` always returns a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Further action required to meet 2020 fuel quality targets despite 3.7% drop in greenhouse gas intensity since 2010\n",
      "Carbon Market Report: Emissions from EU ETS stationary installations fall by over 9%\n",
      "Start of phase 4 of the EU ETS in 2021: adoption of the cap and start of the auctions\n",
      "LIFE programme: over EUR 280 million in EU funding for environment, nature and climate action projects\n",
      "Commission launches four public consultations in an important step towards climate neutrality\n",
      "First Innovation Fund call for large-scale projects: 311 applications for the EUR 1 billion EU funding for clean tech projects\n",
      "Commission to launch four public consultations in an important step towards climate neutrality\n",
      "Commission sets Forest Reference Levels in a delegated act\n",
      "EU recognises best nature, environment and climate action projects\n",
      "Opening Remarks by Executive Vice-President Frans Timmermans at the European Parliament Plenary Session on the European Climate Law\n"
     ]
    }
   ],
   "source": [
    "span_soup = eu_soup.find_all(\"span\", class_ = \"views-field-title\")\n",
    "news_titles_soup = [soup.find(\"a\") for soup in span_soup]\n",
    "news_titles_soup = list(filter(None, news_titles_soup)) # Filtering empty\n",
    "\n",
    "for title in news_titles_soup:\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also store the titles as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Further action required to meet 2020 fuel quality targets despite 3.7% drop in greenhouse gas intensity since 2010', 'Carbon Market Report: Emissions from EU ETS stationary installations fall by over 9%', 'Start of phase 4 of the EU ETS in 2021: adoption of the cap and start of the auctions', 'LIFE programme: over EUR 280 million in EU funding for environment, nature and climate action projects', 'Commission launches four public consultations in an important step towards climate neutrality', 'First Innovation Fund call for large-scale projects: 311 applications for the EUR 1 billion EU funding for clean tech projects', 'Commission to launch four public consultations in an important step towards climate neutrality', 'Commission sets Forest Reference Levels in a delegated act', 'EU recognises best nature, environment and climate action projects', 'Opening Remarks by Executive Vice-President Frans Timmermans at the European Parliament Plenary Session on the European Climate Law']\n"
     ]
    }
   ],
   "source": [
    "title_list = [title_soup.get_text() for title_soup in news_titles_soup]\n",
    "print(title_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/clima/news/further-action-required-meet-2020-fuel-quality-targets-despite-37-drop-greenhouse-gas-intensity_en\n",
      "/clima/news/carbon-market-report-emissions-eu-ets-stationary-installations-fall-over-9_en\n",
      "/clima/news/start-phase-4-eu-ets-2021-adoption-cap-and-start-auctions_en\n",
      "https://ec.europa.eu/commission/presscorner/detail/en/ip_20_2052\n",
      "/clima/news/commission-launches-four-public-consultations-important-step-towards-climate-neutrality_en\n",
      "/clima/news/first-innovation-fund-call-large-scale-projects-311-applications-eur-1-billion-eu-funding-clean_en\n",
      "/clima/news/commission-launch-four-public-consultations-important-step-towards-climate-neutrality_en\n",
      "/clima/news/commission-sets-forest-reference-levels-delegated-act_en\n",
      "https://ec.europa.eu/environment/news/eu-recognises-best-nature-environment-and-climate-action-projects-2020-10-21_en\n",
      "https://ec.europa.eu/commission/commissioners/2019-2024/timmermans/announcements/opening-remarks-executive-vice-president-frans-timmermans-european-parliament-plenary-session_en\n"
     ]
    }
   ],
   "source": [
    "for title in news_titles_soup:\n",
    "    print(title['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stored as a list of links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/clima/news/further-action-required-meet-2020-fuel-quality-targets-despite-37-drop-greenhouse-gas-intensity_en', '/clima/news/carbon-market-report-emissions-eu-ets-stationary-installations-fall-over-9_en', '/clima/news/start-phase-4-eu-ets-2021-adoption-cap-and-start-auctions_en', 'https://ec.europa.eu/commission/presscorner/detail/en/ip_20_2052', '/clima/news/commission-launches-four-public-consultations-important-step-towards-climate-neutrality_en', '/clima/news/first-innovation-fund-call-large-scale-projects-311-applications-eur-1-billion-eu-funding-clean_en', '/clima/news/commission-launch-four-public-consultations-important-step-towards-climate-neutrality_en', '/clima/news/commission-sets-forest-reference-levels-delegated-act_en', 'https://ec.europa.eu/environment/news/eu-recognises-best-nature-environment-and-climate-action-projects-2020-10-21_en', 'https://ec.europa.eu/commission/commissioners/2019-2024/timmermans/announcements/opening-remarks-executive-vice-president-frans-timmermans-european-parliament-plenary-session_en']\n"
     ]
    }
   ],
   "source": [
    "link_list = [title_soup['href'] for title_soup in news_titles_soup]\n",
    "print(link_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to save this list of links as a .txt file, we can write the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"eu_climate_news_links.txt\", 'w') as file: # This line creates a text file in \"write\" mode\n",
    "    for line in link_list: # Iterating over each line in the list (each link)\n",
    "        file.write(line + \"\\n\") # Each link is written to the file followed by a newline (\\n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Extracting information from EU Climate Action News\n",
    "\n",
    "Using the right tags and attributes for search, extract the following from the EU Climate Action News (https://ec.europa.eu/clima/news_en):\n",
    "\n",
    "1. The dates of the news articles.\n",
    "\n",
    "2. The summaries of the news articles.\n",
    "\n",
    "3. The urls for the images used for the news articles.\n",
    "\n",
    "If you are familiar with Python dictionaries and lists, see if you can collect the data in a format that allows you to easily find the summary for a specific article later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting summaries\n",
    "\n",
    "The summaries are inside a div tag with the class \"views-field-field-summary\". The summaries can therefore be extracted as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' The Commission today adopted its 2018 Fuel Quality Report based on the data submitted by EU countries. According to the data provided, the average greenhouse gas intensity of fuels in the 28 reporting Member States had fallen by 3.7% compared to the 2010 baseline. The year-on-year progress achieved compared to 2017 was limited to a 0.3% decrease. Progress varied greatly across Member States, but almost all need to take swift action to meet the 2020 target of 6%.\\n ', ' The European Commission has adopted its annual report on the functioning of the European carbon market. The report covers 2019 and certain developments in 2020.\\n ', ' The Commission is finalising the preparations for the period 2021-2030 of the EU ETS (phase 4), starting on 1 January 2021.\\n ', ' The European Commission has approved an investment package of more than EUR 280 million from the EU budget for over 120 new LIFE programme projects. This EU funding will trigger total investments of nearly EUR 590 million to help meet these projects’ ambitious goals for environment, nature, and climate action. This amount represents a 37% rise compared to last year.\\n\\n ', ' The European Commission today launched four open public consultations on forthcoming revisions to the laws designed to limit the EU’s emissions of greenhouse gases. The open public consultations refer to the revision of:\\n ', ' In response to the first call for large-scale projects of the Innovation Fund, the European Commission received 311 applications for innovative clean tech projects in renewable energy, energy-intensive industries, energy storage, and carbon capture, use and storage.\\n ', ' The European Commission today announced its plan to launch open public consultations on forthcoming revisions to the laws designed to limit the EU’s emissions of greenhouse gases.\\n ', ' The Commission has today adopted the forest reference levels (FRLs) for each Member State to apply between 2021 and 2025. FRLs are benchmarks to calculate the sum of greenhouse gas removals and emissions from existing forests in each Member State. CO2 removal from existing forestland is the backbone of the EU land use sink.\\n ', ' Europe’s biggest environmental event, EU Green Week, hosted today the 2020 LIFE Awards Ceremony. Presented by the EU’s LIFE programme for environment and climate action, the awards honoured winners in three different categories from Slovenia (Nature), Portugal (Environment), and Hungary (Climate Action). A special award recognising successful adaptation to COVID-19 went to an Italian project for its work in the time of coronavirus crisis.\\n ', ' Madame President, Honourable Members,\\nFirst of all, I have to apologize for being late, it is because of the College, it finished now and I immediately came here.\\nI am really happy to discuss with you today which is I think a landmark for the European Green Deal: the Climate Law to turn Europe’s political climate ambitions into binding legislation...\\n ']\n"
     ]
    }
   ],
   "source": [
    "summaries_soup = eu_soup.find_all(\"div\", class_=\"views-field-field-summary\")\n",
    "\n",
    "summaries_text = [summary_soup.get_text() for summary_soup in summaries_soup]\n",
    "\n",
    "print(summaries_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collected the data in a structured format\n",
    "\n",
    "To make it easier to work with the data later on, we can extract the information and structure it in some sensible format.\n",
    "\n",
    "In the following, the title, link, date, summary and image URL of each news article is stored as a dictionary (`article_dict`). The articles are gathered in a list.\n",
    "\n",
    "This format is essentially a list of JSONs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_rows_soup = eu_soup.find_all(\"div\", class_ = \"views-row\")\n",
    "\n",
    "article_list = []\n",
    "\n",
    "for row in article_rows_soup:\n",
    "    article_dict = {}\n",
    "    \n",
    "    article_title_soup = row.find(\"span\", class_ = \"views-field-title\").find(\"a\")\n",
    "    article_title = article_title_soup.get_text()\n",
    "    article_link = article_title_soup['href']\n",
    "    \n",
    "    article_date = row.find(\"span\", class_ = \"date-display-single\").get_text()\n",
    "    \n",
    "    article_summary_soup = row.find(\"div\", class_ = \"views-field-field-summary\")\n",
    "    try:\n",
    "        article_summary = article_summary_soup.get_text(strip = True)\n",
    "    except:\n",
    "        article_summary = \"\"\n",
    "    \n",
    "    article_imgurl = row.find(\"div\", class_ = \"views-field-field-nems-core-image\").find(\"img\")['src']\n",
    "    \n",
    "    article_dict['title'] = article_title\n",
    "    article_dict['link'] = article_link\n",
    "    article_dict['date'] = article_date\n",
    "    article_dict['summary'] = article_summary\n",
    "    article_dict['imgurl'] = article_imgurl\n",
    "    \n",
    "    article_list.append(article_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is now stored as a list of dictionaries: Each list element is a dictionary with the keys title, link, date, summary and imgurl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Further action required to meet 2020 fuel quality targets despite 3.7% drop in greenhouse gas intensity since 2010',\n",
       " 'link': '/clima/news/further-action-required-meet-2020-fuel-quality-targets-despite-37-drop-greenhouse-gas-intensity_en',\n",
       " 'date': '19/11/2020',\n",
       " 'summary': 'The Commission today adopted its2018 Fuel Quality Reportbased on the data submitted by EU countries. According to the data provided, the average greenhouse gas intensity of fuels in the 28 reporting Member States had fallen by 3.7% compared to the 2010 baseline. The year-on-year progress achieved compared to2017was limited to a 0.3% decrease. Progress varied greatly across Member States, but almost all need to take swift action to meet the 2020 target of 6%.',\n",
       " 'imgurl': 'https://ec.europa.eu/clima/sites/clima/files/styles/news-events/public/news/images/20180206.jpg?itok=suQn3NdR'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format can be converted to a pandas data frame with `pd.DataFrame.from_records()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eu_df = pd.DataFrame.from_records(article_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "      <th>imgurl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Further action required to meet 2020 fuel qual...</td>\n",
       "      <td>/clima/news/further-action-required-meet-2020-...</td>\n",
       "      <td>19/11/2020</td>\n",
       "      <td>The Commission today adopted its2018 Fuel Qual...</td>\n",
       "      <td>https://ec.europa.eu/clima/sites/clima/files/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carbon Market Report: Emissions from EU ETS st...</td>\n",
       "      <td>/clima/news/carbon-market-report-emissions-eu-...</td>\n",
       "      <td>18/11/2020</td>\n",
       "      <td>The European Commission has adopted its annual...</td>\n",
       "      <td>https://ec.europa.eu/clima/sites/clima/files/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Start of phase 4 of the EU ETS in 2021: adopti...</td>\n",
       "      <td>/clima/news/start-phase-4-eu-ets-2021-adoption...</td>\n",
       "      <td>17/11/2020</td>\n",
       "      <td>The Commission is finalising the preparations ...</td>\n",
       "      <td>https://ec.europa.eu/clima/sites/clima/files/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIFE programme: over EUR 280 million in EU fun...</td>\n",
       "      <td>https://ec.europa.eu/commission/presscorner/de...</td>\n",
       "      <td>16/11/2020</td>\n",
       "      <td>The European Commission has approved an invest...</td>\n",
       "      <td>https://ec.europa.eu/clima/sites/clima/files/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Commission launches four public consultations ...</td>\n",
       "      <td>/clima/news/commission-launches-four-public-co...</td>\n",
       "      <td>13/11/2020</td>\n",
       "      <td>The European Commission today launched four op...</td>\n",
       "      <td>https://ec.europa.eu/clima/sites/clima/files/s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Further action required to meet 2020 fuel qual...   \n",
       "1  Carbon Market Report: Emissions from EU ETS st...   \n",
       "2  Start of phase 4 of the EU ETS in 2021: adopti...   \n",
       "3  LIFE programme: over EUR 280 million in EU fun...   \n",
       "4  Commission launches four public consultations ...   \n",
       "\n",
       "                                                link        date  \\\n",
       "0  /clima/news/further-action-required-meet-2020-...  19/11/2020   \n",
       "1  /clima/news/carbon-market-report-emissions-eu-...  18/11/2020   \n",
       "2  /clima/news/start-phase-4-eu-ets-2021-adoption...  17/11/2020   \n",
       "3  https://ec.europa.eu/commission/presscorner/de...  16/11/2020   \n",
       "4  /clima/news/commission-launches-four-public-co...  13/11/2020   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The Commission today adopted its2018 Fuel Qual...   \n",
       "1  The European Commission has adopted its annual...   \n",
       "2  The Commission is finalising the preparations ...   \n",
       "3  The European Commission has approved an invest...   \n",
       "4  The European Commission today launched four op...   \n",
       "\n",
       "                                              imgurl  \n",
       "0  https://ec.europa.eu/clima/sites/clima/files/s...  \n",
       "1  https://ec.europa.eu/clima/sites/clima/files/s...  \n",
       "2  https://ec.europa.eu/clima/sites/clima/files/s...  \n",
       "3  https://ec.europa.eu/clima/sites/clima/files/s...  \n",
       "4  https://ec.europa.eu/clima/sites/clima/files/s...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
