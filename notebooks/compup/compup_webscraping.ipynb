{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Web Scraping with Python\n",
    "\n",
    "This notebook introduces the basic tools for web scraping with Python:\n",
    "\n",
    "- What is web scraping?\n",
    "- Accessing a webpage\n",
    "- Extracting source code from a webpage (HTML)\n",
    "- Parsing and navigating HTML with `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is web scraping?\n",
    "\n",
    "\"Web scraping\" is an umbrella term for (mostly) automated techniques for collecting information from the web (usually refers to collection *not* done manually in a browser).\n",
    "\n",
    "Crawling, scraping and spiders are all various forms of scraping. Programs/scripts written for scraping can also be refered to as robots.\n",
    "\n",
    "Working with web scraping involves the collection of *raw data* (source code) from the web as well as handling and converting these data to a manageable and analyzable format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"legality\" of web scraping\n",
    "\n",
    "### Web scraping and copyright\n",
    "\n",
    "The information and material on company and organisation websites are owned by those companies and organisations. A lot of websites have terms of use that prohibit the use of scraping or automated methods of collection on their websites. This is partly due to the fact that one can create a website with scrapers that duplicate the content of other websites. Even though this may not be our intention with the scraping that we do, it will often be considered a violation of the website's terms.\n",
    "\n",
    "### Web scraping and personal data\n",
    "\n",
    "Data on social media are a particular grey area when it comes to personal data. Is data that people voluntarily make available on public social media profiles still their data? A website like Twitter for example clearly states that all data made available on their platform is to be considered public information. Even so, a case could still be made that the data is still personal; just publicly available personal data.\n",
    "\n",
    "Websites like Facebook, Twitter and Instagram also have terms of use for their data as they are responsible for it. Facebook and Instagram for exmaple do not allow any forms of automated collection of data.\n",
    "\n",
    "### Web scraping og \"hacking\"\n",
    "\n",
    "A website is located on a server. Each time a website is visited, a server is receiving a request to be processed. The more requests, the more busy the server is. Python allows us to easily write commands that send an incredible amount of requests within a very short time.\n",
    "\n",
    "*This can easily be considered an attack and an attempt to congest a server which is illegal!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the internet with Python\n",
    "\n",
    "The package `requests` can be used to send requests over the internet. \n",
    "\n",
    "When visiting a webpage, you are sending a \"get\" request to the server where the webpage is hosted. \n",
    "\n",
    "In Python, a get request can be send with `requests.get(url)`. This returns a request object (or a class) containing various attributes like the status code, headers and content.\n",
    "\n",
    "In the code below, we send a request to the news overview for the EU's Climate Action section (https://ec.europa.eu/clima/news_en)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # Importing the package\n",
    "\n",
    "response = requests.get(\"https://ec.europa.eu/clima/news_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`response` is now a request object containing various information of that request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the request\n",
    "\n",
    "To check if the request was successful, we can check the status code by inspecting the attribute `.status_code`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status code 200 means \"OK\"; that our request was succesul. \n",
    "\n",
    "This can be verified by checking the attribute `.reason`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n"
     ]
    }
   ],
   "source": [
    "print(response.status_code, response.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick note on status codes**\n",
    "\n",
    "- Status codes beginning with 2 or 3: The request is successful\n",
    "- Status codes beginning with 4: The request has failed (client-side, fx 404 when specifying a URL that does not exist on a given domain).\n",
    "- Status codes beginning with 5: The request has failed (server-side)\n",
    "\n",
    "Status codes can be used in code to check whether or not a site is reached before scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content of a webpage\n",
    "\n",
    "The raw source code from a webpage can be extracted from the attribute `.content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html lang=\"en\" dir=\"ltr\" prefix=\"og: https://ogp.me/ns#\">\\n  <head>\\n    <meta charset=\"utf-8\" />\\n<script type=\"application/json\">{\"service\":\"etrans\",\"renderAs\":{\"icon\":false,\"button\":false,\"link\":true},\"renderTo\":\"webtools-etrans\",\"include\":\"#block-ewcms-theme-main-page-content,#block-ewcms-theme-navigation-block,.ecl-page-header-standardised__title,.ecl-page-header-standardised__description,.ecl-page-header-core__title,.ecl-page-header-core__description,nav.ecl-menu,.ecl-site-header-standardised__site-name\",\"languages\":{\"source\":\"en\",\"exclude\":[\"en\"]}}</script>\\n<link rel=\"canonical\" href=\"https://ec.europa.eu/clima/news-your-voice/news_en\" />\\n<meta http-equiv=\"content-language\" content=\"en\" />\\n<meta name=\"description\" content=\"Climate newsroom\" />\\n<meta property=\"og:determiner\" content=\"auto\" />\\n<meta property=\"og:site_name\" content=\"Climate Action\" />\\n<meta property=\"og:type\" content=\"website\" />\\n<meta property=\"og:url\" content=\"https://ec.europa.eu/clima/news-your-vo'\n"
     ]
    }
   ],
   "source": [
    "content = response.content\n",
    "print(content[0:1000]) # Printing first 1000 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this raw source code, one *could* process this as is using something like regular expression to find the relevant parts of the source code.\n",
    "\n",
    "However, HTML has a certain structure. This can be utilized to extract specific information from a webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick introduction to HTML\n",
    "\n",
    "Instead of processing the HTML as raw text, we can utilize the structure of HTML to extract specific parts of a webpage.\n",
    "\n",
    "This requires some knowledge of what HTML is and how it is structured.\n",
    "\n",
    "HTML is short for \"Hyper-Text Markup Language\". It is used on webpages to give the pages their structure.\n",
    "\n",
    "HTML is structured in \"tags\" denoted by `<>` and `</>`. The tags denote what kind of content it is. `<p>` is for example a paragraph tag. A piece of HTML like: `<p> This is a paragraph </p>` will render the sentence \"This is a paragraph\" as a paragraph. Common tags include `h1` for headings (and `h2`, `h3` and so on), `a` for links and `div` for a \"division\" or \"section\".\n",
    "\n",
    "HTML is structured in a tree-like structure. Tags are therefore usually located within other tags. Tags on the same level are refered to as \"siblings\", tags inside other tags are refered to as \"children\" and tags outside other tags are refered to as \"parents\".\n",
    "\n",
    "HTML uses \"attributes\" to both differentiate between the same type of tags and to add other variables/information to the tag. The `id` attribute is fx used to give several tags a common id. `class` is used to differentiate between different tags and provide them with different stylings. A common and useful attribute is `href` which contain the link that a hyperlink is refering to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    <html>\n",
    "        <body>\n",
    "            <div id=\"convo1\">\n",
    "                <p class=\"kenobi\">Hello There!</p>\n",
    "            </div>\n",
    "            <div id=\"convo2\">\n",
    "                <p class=\"grievous\">General Kenobi!</p>\n",
    "            </div>\n",
    "            <div id=\"convo3\">\n",
    "                <p class=\"kenobi\">So Uncivilized!</p>\n",
    "            </div>\n",
    "        </body>\n",
    "    </html>\n",
    "```    \n",
    "\n",
    "\n",
    "The code above is an example of HTML code. Rendered as a webpage it would only contain the text within the tags:\n",
    "\n",
    "```\n",
    "Hello There!\n",
    "\n",
    "General Kenobi!\n",
    "\n",
    "So Uncivilized!\n",
    "```\n",
    "\n",
    "The structure and the tags of the HTML allows us to extract only specific parts of the code. This is because the structure and the tags makes certain part of the code uniquely identifiable. For example:\n",
    "\n",
    "- The text \"Hello There!\" is located within a p tag with the class \"kenobi\". \n",
    "- The p tag containing the text \"Hello There!\" is located within the div tag with id \"convo1\" (tags located inside other tags are refered to as \"children\")\n",
    "- The div tag with id \"convo1\" is located next to another div tag with id \"convo2\" (tags located next to each other or on the same level are refered to as \"siblings\")\n",
    "\n",
    "Combining the information, we can uniquely refer to the tag containing \"Hello There!\" by specifying that we want a p tag with class \"kenobi\" that is a child of a div tag with id \"convo1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing HTML with BeautifulSoup\n",
    "\n",
    "The package \"BeautifulSoup\" (https://www.crummy.com/software/BeautifulSoup/bs4/doc/) is developed specifically to navigate and parsing HTML (and XML) code. It works by converting HTML code to a \"soup-object\" wherein specific parts of the HTML can be extracted by refering to specific tags or paths.\n",
    "\n",
    "The code below converts the HTML from before to a soup object using the function `bs`, which is a shorthand for the function `BeautifulSoup` imported from `bs4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "html = '<html><body><div id=\"convo1\"><p class=\"kenobi\">Hello There!</p></div><div id=\"convo2\"><p class=\"grievous\">General Kenobi!</p></div><div id=\"convo3\"><p class=\"kenobi\">So Uncivilized!</p></div></body></html>'\n",
    "soup = bs(html, \"html.parser\") # The second arguement specifies the parser to use; how the code should be interpreted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <div id=\"convo1\">\n",
      "   <p class=\"kenobi\">\n",
      "    Hello There!\n",
      "   </p>\n",
      "  </div>\n",
      "  <div id=\"convo2\">\n",
      "   <p class=\"grievous\">\n",
      "    General Kenobi!\n",
      "   </p>\n",
      "  </div>\n",
      "  <div id=\"convo3\">\n",
      "   <p class=\"kenobi\">\n",
      "    So Uncivilized!\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()) # Prints the HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When printed with `.prettify()` it looks like the same text but we are now able to navigate it using the tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding tags\n",
    "\n",
    "The methods `.find()` and `.find_all()` are used to find the first match and all matches respectively. The first argument of the method is the tag. Other arguments can then be added to make the search more specific.\n",
    "\n",
    "Note that `.find()` and `.find_all()` are methods tied to a soup object, so they have to be used with some object returned from `bs` (in this case the object `soup` created earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"kenobi\">Hello There!</p>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\") # Finds the first p tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.find()` returns a new soup object with the HTML in the first matched tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"kenobi\">Hello There!</p>,\n",
       " <p class=\"grievous\">General Kenobi!</p>,\n",
       " <p class=\"kenobi\">So Uncivilized!</p>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\") # Finds all p tags (returned as a list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.find_all()` returns a list of soup objects with the HTML in the matched tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `.get_text()` extracts the actual textual content within the tag (between `<p>` and `</p>` in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello There!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\").get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.get_text()` works on a soup object and therefore not on returns from `find_all()`, as that returns a list. To extract the text from the contents of a list returned from `find_all()`, we have to iterate over the list elements (fx with a for loop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello There!\n",
      "General Kenobi!\n",
      "So Uncivilized!\n"
     ]
    }
   ],
   "source": [
    "for tag in soup.find_all(\"p\"):\n",
    "    print(tag.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using attributes to find tags\n",
    "\n",
    "In addition to searching for tags, we can also specify attributes. Some attributes have arguments specific for them like id and class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for a div tag with a specific id attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello There!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"div\", id = \"convo1\").get_text() # Search for a specific id attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `.get_text()` extracts *all* text within the tag including text within child tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for class attribute (notice the `_` added to `class_` as the `class` name is reserved somewhere else in Python):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello There!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\", class_ = \"kenobi\").get_text() # Search for a specific class attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags can also be found by searching for the attribute alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello There!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(class_ = \"kenobi\").get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup supports a wide range of attributes (id, href, class). There are however no real rules as to what attributes can be called in HTML. BeautifulSoup therefore supports searching for any attribute with the following syntax:\n",
    "\n",
    "`attrs = {\"attribute\": \"value\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello There!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(attrs = {\"class\": \"kenobi\"}).get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knowledge check:\n",
    "\n",
    "What tags or attributes can be used to extract the text \"General Kenobi\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <div id=\"convo1\">\n",
      "   <p class=\"kenobi\">\n",
      "    Hello There!\n",
      "   </p>\n",
      "  </div>\n",
      "  <div id=\"convo2\">\n",
      "   <p class=\"grievous\">\n",
      "    General Kenobi!\n",
      "   </p>\n",
      "  </div>\n",
      "  <div id=\"convo3\">\n",
      "   <p class=\"kenobi\">\n",
      "    So Uncivilized!\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the right tags\n",
    "\n",
    "Let us try applying some of these skills on the European Union Climate Action news section.\n",
    "\n",
    "We already know how to get the HTML, so this just has to be converted to a soup object, and we are ready to go. \n",
    "\n",
    "We first send a GET request and store the response as an object. As a lot of things can go wrong with a request, we check whether the request actually got through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://ec.europa.eu/clima/news_en\")\n",
    "\n",
    "print(response.status_code, response.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output from the code above says \"200 OK\", we are ready to create the soup object from the HTML of the website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_html = response.content\n",
    "\n",
    "eu_soup = bs(eu_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the right tags by just browing through raw HTML is not ideal.\n",
    "\n",
    "Instead we can use our browser to help us find the parts of the webpage to extract. Almost all browsers has an \"inspector tool\" of some kind that allows one to inspect the source code of a webpage (shortcut `F12` for a lot of browsers on Windows and `Command-Option-I` for Safari on Mac)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting news headlines from EU Climate Action News\n",
    "\n",
    "Inspecting the HTML of https://ec.europa.eu/clima/news_en, we see that the headlines are part of an \"a\" tag within a div tag with the class \"ecl-content-item__title\". This class seems to be unique for the headlines.\n",
    "\n",
    "We can extract the first headline as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emissions trading: greenhouse gas emissions up by 7.3% in 2021 compared with 2020\n"
     ]
    }
   ],
   "source": [
    "news_title_soup = eu_soup.find(\"div\", class_ = \"ecl-content-item__title\").find(\"a\") # The find methods are chained; first span, then a\n",
    "\n",
    "print(news_title_soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the div tag in question actually contains two classes: \"ecl-content-item__title\" and \"ecl-u-type-heading-5\" (among others). HTML class names cannot contain spaces, so when an HTML tag contains a class attribute that contains spaces, it is actually two classes. When specifying the class with `.find()` or `.find_all()`, we only have to specify one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The headline is also a link. Links are almost always created as an \"a\" tag.\n",
    "\n",
    "`news_title_soup` is currently the soup object with the \"a\" tag containing the headline. Supposing we want to collect the links to the articles to scrape the articles themselves, we can extract that directly from this soup object.\n",
    "\n",
    "The URL linked is almost always stored as an \"href\" attribute in an \"a\" tag.\n",
    "\n",
    "Attributes can be extracted directly from soup objects using `[attribute]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/clima/news-your-voice/news/emissions-trading-greenhouse-gas-emissions-73-2021-compared-2020-2022-04-25_en'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_title_soup['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links can be either \"absolute\" or \"relative\". Absolute links contain the entire URL to access the page. A relative URL contains the path on the specific domain. \n",
    "\n",
    "In order to convert the output a both to a working URL, we have to add the main domain, which can be done via pasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ec.europa.eu/clima/news-your-voice/news/emissions-trading-greenhouse-gas-emissions-73-2021-compared-2020-2022-04-25_en\n"
     ]
    }
   ],
   "source": [
    "print(\"https://ec.europa.eu\" + news_title_soup['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting all headlines\n",
    "\n",
    "Extracting all the titles will have to be done step-wise, as `.find_all()` cannot be chained the same way because `.find_all()` always returns a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emissions trading: greenhouse gas emissions up by 7.3% in 2021 compared with 2020\n",
      "Joint Statement European Union - Egypt\n",
      "EU Emissions Trading System - compliance information for 2021\n",
      "Green Deal: Phasing down fluorinated greenhouse gases and ozone depleting substances\n",
      "United Nations’ science panel issues starkest warning yet to urgently cut global emissions\n",
      "Commission awards over €1 billion to innovative projects for the EU climate transition\n",
      "Commission makes available €100 million for innovative clean technology projects\n",
      "Commission invites regions and communities to join the Mission Adaptation to Climate Change\n",
      "€1.5 billion for clean tech: 138 projects apply to the EU Innovation Fund’s second call for large-scale projects\n",
      "Urgent need to adapt to massive impacts of climate change highlighted in latest IPCC report\n",
      "Green Deal: EU invests over €110 million in LIFE projects for environment and climate in 11 EU countries \n",
      "Executive Vice-President Frans Timmermans travels to Vietnam for a three-day visit\n",
      "Revised 2022 auction calendar for general allowances published\n",
      "More than €7 million in LIFE funding for NGOs\n",
      "EU-Catalyst Partnership: Request for proposals of pioneering green technology projects is launched\n",
      "European Citizens’ Panel finalises recommendations for more sustainable and healthy Europe\n",
      "Commission is looking for top experts to advise on EU Missions\n",
      "Modernisation Fund invests nearly €900 million during first year of operation\n",
      "Further 2022 auction calendars published\n",
      "Commission awards 27 grants under the Innovation Fund\n"
     ]
    }
   ],
   "source": [
    "span_soup = eu_soup.find_all(\"div\", class_ = \"ecl-content-item__title\")\n",
    "news_titles_soup = [title_soup.find(\"a\") for title_soup in span_soup]\n",
    "news_titles_soup = list(filter(None, news_titles_soup)) # Filtering empty\n",
    "\n",
    "for title in news_titles_soup:\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also store the titles as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emissions trading: greenhouse gas emissions up by 7.3% in 2021 compared with 2020\n",
      "Joint Statement European Union - Egypt\n",
      "EU Emissions Trading System - compliance information for 2021\n",
      "Green Deal: Phasing down fluorinated greenhouse gases and ozone depleting substances\n",
      "United Nations’ science panel issues starkest warning yet to urgently cut global emissions\n",
      "Commission awards over €1 billion to innovative projects for the EU climate transition\n",
      "Commission makes available €100 million for innovative clean technology projects\n",
      "Commission invites regions and communities to join the Mission Adaptation to Climate Change\n",
      "€1.5 billion for clean tech: 138 projects apply to the EU Innovation Fund’s second call for large-scale projects\n",
      "Urgent need to adapt to massive impacts of climate change highlighted in latest IPCC report\n",
      "Green Deal: EU invests over €110 million in LIFE projects for environment and climate in 11 EU countries \n",
      "Executive Vice-President Frans Timmermans travels to Vietnam for a three-day visit\n",
      "Revised 2022 auction calendar for general allowances published\n",
      "More than €7 million in LIFE funding for NGOs\n",
      "EU-Catalyst Partnership: Request for proposals of pioneering green technology projects is launched\n",
      "European Citizens’ Panel finalises recommendations for more sustainable and healthy Europe\n",
      "Commission is looking for top experts to advise on EU Missions\n",
      "Modernisation Fund invests nearly €900 million during first year of operation\n",
      "Further 2022 auction calendars published\n",
      "Commission awards 27 grants under the Innovation Fund\n"
     ]
    }
   ],
   "source": [
    "title_list = [title_soup.get_text() for title_soup in news_titles_soup]\n",
    "\n",
    "for title in title_list:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting article links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/clima/news-your-voice/news/emissions-trading-greenhouse-gas-emissions-73-2021-compared-2020-2022-04-25_en\n",
      "/clima/news-your-voice/news/joint-statement-european-union-egypt-2022-04-11_en\n",
      "/clima/news-your-voice/news/eu-emissions-trading-system-compliance-information-2021-2022-04-07_en\n",
      "https://ec.europa.eu/commission/presscorner/detail/en/ip_22_2189\n",
      "/clima/news-your-voice/news/united-nations-science-panel-issues-starkest-warning-yet-urgently-cut-global-emissions-2022-04-04_en\n",
      "https://ec.europa.eu/commission/presscorner/detail/en/ip_22_2163\n",
      "/clima/news-your-voice/news/commission-makes-available-eu100-million-innovative-clean-technology-projects-2022-03-31_en\n",
      "/clima/news-your-voice/news/commission-invites-regions-and-communities-join-mission-adaptation-climate-change-2022-03-14_en\n",
      "/clima/news-your-voice/news/eu15-billion-clean-tech-138-projects-apply-eu-innovation-funds-second-call-large-scale-projects-2022-03-11_en\n",
      "/clima/news-your-voice/news/urgent-need-adapt-massive-impacts-climate-change-highlighted-latest-ipcc-report-2022-02-28_en\n",
      "https://ec.europa.eu/commission/presscorner/detail/en/IP_22_864\n",
      "/clima/news-your-voice/news/executive-vice-president-frans-timmermans-travels-vietnam-three-day-visit-2022-02-16_en\n",
      "/clima/news-your-voice/news/revised-2022-auction-calendar-general-allowances-published-2022-02-16_en\n",
      "https://cinea.ec.europa.eu/news/more-eu7-million-life-funding-ngos-2022-01-25_en\n",
      "https://ec.europa.eu/info/news/eu-catalyst-partnership-request-proposals-pioneering-green-technology-projects-launched-2022-jan-11_en\n",
      "/clima/news-your-voice/news/european-citizens-panel-finalises-recommendations-more-sustainable-and-healthy-europe-2022-01-06_en\n",
      "/clima/news-your-voice/news/commission-looking-top-experts-advise-eu-missions-2022-01-06_en\n",
      "/clima/news-your-voice/news/modernisation-fund-invests-nearly-eu900-million-during-first-year-operation-2021-12-16_en\n",
      "/clima/news-your-voice/news/further-2022-auction-calendars-published-2021-12-15_en\n",
      "/clima/news-your-voice/news/commission-awards-27-grants-under-innovation-fund-2021-12-10_en\n"
     ]
    }
   ],
   "source": [
    "for title in news_titles_soup:\n",
    "    print(title['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stored as a list of links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/clima/news-your-voice/news/emissions-trading-greenhouse-gas-emissions-73-2021-compared-2020-2022-04-25_en\n",
      "/clima/news-your-voice/news/joint-statement-european-union-egypt-2022-04-11_en\n",
      "/clima/news-your-voice/news/eu-emissions-trading-system-compliance-information-2021-2022-04-07_en\n",
      "https://ec.europa.eu/commission/presscorner/detail/en/ip_22_2189\n",
      "/clima/news-your-voice/news/united-nations-science-panel-issues-starkest-warning-yet-urgently-cut-global-emissions-2022-04-04_en\n",
      "https://ec.europa.eu/commission/presscorner/detail/en/ip_22_2163\n",
      "/clima/news-your-voice/news/commission-makes-available-eu100-million-innovative-clean-technology-projects-2022-03-31_en\n",
      "/clima/news-your-voice/news/commission-invites-regions-and-communities-join-mission-adaptation-climate-change-2022-03-14_en\n",
      "/clima/news-your-voice/news/eu15-billion-clean-tech-138-projects-apply-eu-innovation-funds-second-call-large-scale-projects-2022-03-11_en\n",
      "/clima/news-your-voice/news/urgent-need-adapt-massive-impacts-climate-change-highlighted-latest-ipcc-report-2022-02-28_en\n",
      "https://ec.europa.eu/commission/presscorner/detail/en/IP_22_864\n",
      "/clima/news-your-voice/news/executive-vice-president-frans-timmermans-travels-vietnam-three-day-visit-2022-02-16_en\n",
      "/clima/news-your-voice/news/revised-2022-auction-calendar-general-allowances-published-2022-02-16_en\n",
      "https://cinea.ec.europa.eu/news/more-eu7-million-life-funding-ngos-2022-01-25_en\n",
      "https://ec.europa.eu/info/news/eu-catalyst-partnership-request-proposals-pioneering-green-technology-projects-launched-2022-jan-11_en\n",
      "/clima/news-your-voice/news/european-citizens-panel-finalises-recommendations-more-sustainable-and-healthy-europe-2022-01-06_en\n",
      "/clima/news-your-voice/news/commission-looking-top-experts-advise-eu-missions-2022-01-06_en\n",
      "/clima/news-your-voice/news/modernisation-fund-invests-nearly-eu900-million-during-first-year-operation-2021-12-16_en\n",
      "/clima/news-your-voice/news/further-2022-auction-calendars-published-2021-12-15_en\n",
      "/clima/news-your-voice/news/commission-awards-27-grants-under-innovation-fund-2021-12-10_en\n"
     ]
    }
   ],
   "source": [
    "link_list = [title_soup['href'] for title_soup in news_titles_soup]\n",
    "\n",
    "for link in link_list:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting dates\n",
    "\n",
    "The dates are inside a \"time\" tag within the \"datetime\" attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-25T12:00:00Z\n",
      "2022-04-11T12:00:00Z\n",
      "2022-04-07T12:00:00Z\n",
      "2022-04-05T12:00:00Z\n",
      "2022-04-04T12:00:00Z\n",
      "2022-04-01T12:00:00Z\n",
      "2022-03-31T12:00:00Z\n",
      "2022-03-14T12:00:00Z\n",
      "2022-03-11T12:00:00Z\n",
      "2022-02-28T12:00:00Z\n",
      "2022-02-17T12:00:00Z\n",
      "2022-02-16T12:00:00Z\n",
      "2022-02-16T12:00:00Z\n",
      "2022-01-25T12:00:00Z\n",
      "2022-01-11T12:00:00Z\n",
      "2022-01-06T12:00:00Z\n",
      "2022-01-06T12:00:00Z\n",
      "2021-12-16T12:00:00Z\n",
      "2021-12-15T12:00:00Z\n",
      "2021-12-10T12:00:00Z\n"
     ]
    }
   ],
   "source": [
    "dates_soup = eu_soup.find_all(\"time\")\n",
    "\n",
    "dates = [date_soup[\"datetime\"] for date_soup in dates_soup]\n",
    "\n",
    "for date in dates:\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting summaries\n",
    "\n",
    "The summaries are inside a div tag with the class \"ecl-content-item__description\". The summaries can therefore be extracted as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greenhouse gas emissions from operators covered by the EU Emissions Trading System (EU ETS) increased by 7.3% in 2021 compared with 2020 levels. However, compared with pre-pandemic levels emissions are still on the decline.\n",
      "\n",
      "H.E. Sameh Shoukry, Egyptian Minister of Foreign Affairs and President-designate of the Twenty-Seventh session of the Conference of the Parties to the UNFCCC, received Mr. Frans Timmermans, Executive Vice-President of the European Commission.\n",
      "\n",
      "On 3 May 2022 at 12:00 CEST, the European Commission will publish on the EUTL website the installation-level compliance code for 2021, based on the data available on 30 April, setting out whether an operator surrendered the required amount of allowances.\n",
      "\n",
      "The European Commission has today proposed two new Regulations to more tightly control fluorinated greenhouse gases (F-gases) and ozone depleting substances (ODS).\n",
      "\n",
      "The UN’s Intergovernmental Panel on Climate Change (IPCC) has today published its latest report, setting out the action we need to take to put a brake on global warming, avoid irreversible impacts on our planet and meet the Paris Agreement goal of limiting global temperature rise to 1.5°C.\n",
      "\n",
      "Today, the Commission signed grant agreements of €1.1 billion with seven large-scale projects via the EU Innovation Fund, funded by revenues from the EU’s Emissions Trading System (ETS). These projects aim to reduce emissions by over 76 Mt of CO2eq during the first ten years of operation.\n",
      "\n",
      "Today, the European Commission is launching the second call for small-scale projects under the Innovation Fund, one of the world’s largest funding programmes for the deployment of innovative low-carbon technologies, financed by revenues from the auction of emission allowances from the EU’s ETS.\n",
      "\n",
      "Today, the Commission launched an invitation to EU regions and communities to join the EU Mission on Adaptation to Climate Change. A survey is now available for regions and communities to express their interest in joining the Mission.\n",
      "\n",
      "In response to the Innovation Fund’s second call for large-scale projects, the European Commission received 138 applications for innovative clean tech projects in all eligible categories: renewable energy, energy-intensive industries, energy storage, and carbon capture and storage.\n",
      "\n",
      "The Intergovernmental Panel on Climate Change (IPCC) has today published its latest report on the impacts, adaptation and vulnerabilities related to climate change.\n",
      "\n",
      "Today, the Commission is announcing an investment of over €110 million into LIFE programme integrated projects for environmental and climate protection, selected after a call for proposals covering the year 2020.\n",
      "\n",
      "Executive Vice-President Frans Timmermans is travelling to Vietnam tomorrow, where he will discuss the green transition.\n",
      "\n",
      "Today, the European Energy Exchange (EEX) updated the 2022 auction calendar for general allowances.\n",
      "\n",
      "This special 'LIFE 2020 Call for Proposals from NGOs on the European Green Deal (NGO4GD)' aims to lessen the impact of Covid-19 on the non-profit sector's operations.\n",
      "\n",
      "Today, Breakthrough Energy Catalyst published a request for proposals for large-scale deep green tech projects based in Europe. The request will trigger investments in a portfolio of high-potential projects in the areas of clean hydrogen, sustainable aviation fuels, direct air capture, and ...\n",
      "\n",
      "Eighty Panel representatives will present the outcomes of their respective Panel discussions, and debate them.\n",
      "\n",
      "The European Commission launched a call for experts to join the five Mission Boards, with the role of advising on the implementation of the EU Missions. The five Mission Boards will have up to 15 independent top experts for each Mission.\n",
      "\n",
      "Support for 26 investment proposals in eight beneficiary countries to modernise their energy systems and improve energy efficiency.\n",
      "\n",
      "The European Energy Exchange (EEX) published today the 2022 auction calendars for aviation allowances of the Member States, as well as the 2022 auction calendar for United Kingdom in respect of the generation of electricity in Northern Ireland.\n",
      "\n",
      "Today, 27 projects selected for a grant under the first Innovation Fund call for small-scale projects signed their grant agreement with the European Climate, Infrastructure and Environment Executive Agency (CINEA), the implementing body of the Fund.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summaries_soup = eu_soup.find_all(\"div\", class_=\"ecl-content-item__description\")\n",
    "\n",
    "summaries_text = [summary_soup.get_text() for summary_soup in summaries_soup]\n",
    "\n",
    "for summary in summaries_text:\n",
    "    print(summary + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting the data in a structured format\n",
    "\n",
    "To make it easier to work with the data later on, we can extract the information and structure it in some sensible format.\n",
    "\n",
    "In the following, the title, link, date, summary and image URL of each news article is stored as a dictionary (`article_dict`). The articles are gathered in a list.\n",
    "\n",
    "This format is essentially a list of JSONs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_rows_soup = eu_soup.find_all(\"article\", class_ = \"ecl-content-item\")\n",
    "\n",
    "article_list = []\n",
    "\n",
    "for row in article_rows_soup:\n",
    "    article_dict = {}\n",
    "    \n",
    "    article_title_soup = row.find(\"div\", class_ = \"ecl-content-item__title\").find(\"a\")\n",
    "    article_title = article_title_soup.get_text()\n",
    "    article_link = article_title_soup['href']\n",
    "    \n",
    "    article_date = row.find(\"time\")[\"datetime\"]\n",
    "    \n",
    "    article_summary_soup = row.find(\"div\", class_ = \"ecl-content-item__description\")\n",
    "    try:\n",
    "        article_summary = article_summary_soup.get_text(strip = True)\n",
    "    except:\n",
    "        article_summary = \"\"\n",
    "    \n",
    "    article_dict['title'] = article_title\n",
    "    article_dict['link'] = article_link\n",
    "    article_dict['date'] = article_date\n",
    "    article_dict['summary'] = article_summary\n",
    "    \n",
    "    article_list.append(article_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is now stored as a list of dictionaries: Each list element is a dictionary with the keys title, link, date, summary and imgurl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Emissions trading: greenhouse gas emissions up by 7.3% in 2021 compared with 2020',\n",
       " 'link': '/clima/news-your-voice/news/emissions-trading-greenhouse-gas-emissions-73-2021-compared-2020-2022-04-25_en',\n",
       " 'date': '2022-04-25T12:00:00Z',\n",
       " 'summary': 'Greenhouse gas emissions from operators covered by the EU Emissions Trading System (EU ETS) increased by 7.3% in 2021 compared with 2020 levels. However, compared with pre-pandemic levels emissions are still on the decline.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format can be converted to a pandas data frame with `pd.DataFrame.from_records()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eu_df = pd.DataFrame.from_records(article_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emissions trading: greenhouse gas emissions up...</td>\n",
       "      <td>/clima/news-your-voice/news/emissions-trading-...</td>\n",
       "      <td>2022-04-25T12:00:00Z</td>\n",
       "      <td>Greenhouse gas emissions from operators covere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joint Statement European Union - Egypt</td>\n",
       "      <td>/clima/news-your-voice/news/joint-statement-eu...</td>\n",
       "      <td>2022-04-11T12:00:00Z</td>\n",
       "      <td>H.E. Sameh Shoukry, Egyptian Minister of Forei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EU Emissions Trading System - compliance infor...</td>\n",
       "      <td>/clima/news-your-voice/news/eu-emissions-tradi...</td>\n",
       "      <td>2022-04-07T12:00:00Z</td>\n",
       "      <td>On 3 May 2022 at 12:00 CEST, the European Comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Green Deal: Phasing down fluorinated greenhous...</td>\n",
       "      <td>https://ec.europa.eu/commission/presscorner/de...</td>\n",
       "      <td>2022-04-05T12:00:00Z</td>\n",
       "      <td>The European Commission has today proposed two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Nations’ science panel issues starkest ...</td>\n",
       "      <td>/clima/news-your-voice/news/united-nations-sci...</td>\n",
       "      <td>2022-04-04T12:00:00Z</td>\n",
       "      <td>The UN’s Intergovernmental Panel on Climate Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Emissions trading: greenhouse gas emissions up...   \n",
       "1             Joint Statement European Union - Egypt   \n",
       "2  EU Emissions Trading System - compliance infor...   \n",
       "3  Green Deal: Phasing down fluorinated greenhous...   \n",
       "4  United Nations’ science panel issues starkest ...   \n",
       "\n",
       "                                                link                  date  \\\n",
       "0  /clima/news-your-voice/news/emissions-trading-...  2022-04-25T12:00:00Z   \n",
       "1  /clima/news-your-voice/news/joint-statement-eu...  2022-04-11T12:00:00Z   \n",
       "2  /clima/news-your-voice/news/eu-emissions-tradi...  2022-04-07T12:00:00Z   \n",
       "3  https://ec.europa.eu/commission/presscorner/de...  2022-04-05T12:00:00Z   \n",
       "4  /clima/news-your-voice/news/united-nations-sci...  2022-04-04T12:00:00Z   \n",
       "\n",
       "                                             summary  \n",
       "0  Greenhouse gas emissions from operators covere...  \n",
       "1  H.E. Sameh Shoukry, Egyptian Minister of Forei...  \n",
       "2  On 3 May 2022 at 12:00 CEST, the European Comm...  \n",
       "3  The European Commission has today proposed two...  \n",
       "4  The UN’s Intergovernmental Panel on Climate Ch...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary material on web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Expanding search using regex\n",
    "\n",
    "Attribute values can be long and sometimes adhere to a structure, where we want to find all attributes starting with some value. \n",
    "\n",
    "Instead of passing an exact string match as an arguement for `.find()`, one can instead parse a compiled regular expression pattern to search for.\n",
    "\n",
    "We will not fully explain regular expression here but put shortly, regular expressions is a syntax for writing patterns that can match text strings. Instead of searching specifically for \"kenobi\", one could search for a pattern like starting with \"ken\" (`\"^ken\"`), ends with \"obi\" (`\".*obi$\"`) or contains six letters (`\"\\w{6}\"`).\n",
    "\n",
    "Regular expressions can be compiled using `re.compile(pattern)`. This pattern can the be used in `.find()` and `.find_all()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <div id=\"convo1\">\n",
      "   <p class=\"kenobi\">\n",
      "    Hello There!\n",
      "   </p>\n",
      "  </div>\n",
      "  <div id=\"convo2\">\n",
      "   <p class=\"grievous\">\n",
      "    General Kenobi!\n",
      "   </p>\n",
      "  </div>\n",
      "  <div id=\"convo3\">\n",
      "   <p class=\"kenobi\">\n",
      "    So Uncivilized!\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "html = '<html><body><div id=\"convo1\"><p class=\"kenobi\">Hello There!</p></div><div id=\"convo2\"><p class=\"grievous\">General Kenobi!</p></div><div id=\"convo3\"><p class=\"kenobi\">So Uncivilized!</p></div></body></html>'\n",
    "soup = bs(html, \"html.parser\") # The second arguement specifies the parser to use; how the code should be interpreted\n",
    "print(soup.prettify()) # Prints the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"grievous\">General Kenobi!</p>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "soup.find(class_=re.compile(\"^gri\")) # Search for tags with a class attribute starting with \"gri\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Search for specific text\n",
    "\n",
    "The `.find()` and `.find_all()` methods have a `string = ` arguement to search for specific strings in the text of the HTML. Regular expressions can be used here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello There!'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(string = re.compile(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Navigating the HTML structure\n",
    "\n",
    "Using `.find()` returns a new soup object (`.find_all()` a list of soup objects). Because these methods search for tags *within* the soup object, it is always child tags of the original soup that is returned.\n",
    "\n",
    "This allows one to parse further by first specifying one tag and then another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"kenobi\">Hello There!</p>\n"
     ]
    }
   ],
   "source": [
    "soup_child = soup.find(\"div\")\n",
    "\n",
    "soup_grandchild = soup_child.find(\"p\")\n",
    "\n",
    "print(soup_grandchild)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "It also allows one to navigate the structure, as the extracted soup objects maintains references to the HTML structure that it was extracted from.\n",
    "\n",
    "Using `.parent`, one can locate the tag in which a certain tag is located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"kenobi\">Hello There!</p>\n",
      "<div id=\"convo1\"><p class=\"kenobi\">Hello There!</p></div>\n"
     ]
    }
   ],
   "source": [
    "soup_child = soup.find(\"p\", class_ = \"kenobi\")\n",
    "\n",
    "print(soup_child)\n",
    "\n",
    "print(soup_child.parent) # Returns the parent of soup_child (a div tag in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can also iterate over all parents (and grand parents, so to speak) with `.parents`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div\n",
      "body\n",
      "html\n",
      "[document]\n"
     ]
    }
   ],
   "source": [
    "for parent in soup_child.parents:\n",
    "    print(parent.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Using `.next_sibling` and `.previous_sibling` you can navigate between tags on the same level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div id=\"convo1\"><p class=\"kenobi\">Hello There!</p></div>\n",
      "<div id=\"convo2\"><p class=\"grievous\">General Kenobi!</p></div>\n"
     ]
    }
   ],
   "source": [
    "soup_child = soup.find(\"div\")\n",
    "\n",
    "print(soup_child)\n",
    "\n",
    "print(soup_child.next_sibling) # Returns the next tag on the same level as soup_child"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
